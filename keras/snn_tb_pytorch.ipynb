{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP2vMS9394ZSkPP7u8xYXfP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install snntoolbox\n","!pip install onnx\n","!pip install onnxruntime"],"metadata":{"id":"jfEkkejjgHyK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704301429073,"user_tz":0,"elapsed":50753,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}},"outputId":"84193592-7810-4fb4-db57-cacd3c861546"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting snntoolbox\n","  Downloading snntoolbox-0.6.0-py2.py3-none-any.whl (203 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.9/203.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from snntoolbox) (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (0.35.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (1.60.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->snntoolbox) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->snntoolbox) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->snntoolbox) (3.2.2)\n","Installing collected packages: snntoolbox\n","Successfully installed snntoolbox-0.6.0\n","Collecting onnx\n","  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.15.0\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.16.3\n"]}]},{"cell_type":"code","source":["\"\"\"End-to-end example for SNN Toolbox.\n","\n","This script sets up a small CNN using PyTorch, trains it for one epoch on\n","MNIST, stores model and dataset in a temporary folder on disk, creates a\n","configuration file for SNN toolbox, and finally calls the main function of SNN\n","toolbox to convert the trained ANN to an SNN and run it using INI simulator.\n","\"\"\"\n","\n","import os\n","import shutil\n","import inspect\n","import time\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from tensorflow.keras import backend\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","from snntoolbox.bin.run import main\n","from snntoolbox.utils.utils import import_configparser\n","from tests.parsing.models.pytorch import Model\n","\n","\n","# Pytorch to Keras parser needs image_data_format == channel_first.\n","backend.set_image_data_format('channels_first')\n"],"metadata":{"id":"8GAr_j2pgIsn","executionInfo":{"status":"ok","timestamp":1704301441085,"user_tz":0,"elapsed":12027,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IyUD6m_gWE6","executionInfo":{"status":"ok","timestamp":1704301563502,"user_tz":0,"elapsed":122440,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}},"outputId":"0d928729-48fb-48dd-ef44-fa5cc3182dca"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4bQ0KkQHT5Q0","executionInfo":{"status":"ok","timestamp":1704301928798,"user_tz":0,"elapsed":186,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","execution_count":30,"metadata":{"id":"9pzlepNTfEJR","executionInfo":{"status":"ok","timestamp":1704302021015,"user_tz":0,"elapsed":2931,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}}},"outputs":[],"source":["\n","# WORKING DIRECTORY #\n","#####################\n","\n","# Define path where model and output files will be stored.\n","# The user is responsible for cleaning up this temporary directory.\n","path_wd = '/content/drive/MyDrive/Dissertation/project_code/ann_models/'\n","\n","# GET DATASET #\n","###############\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Normalize input so we can train ANN with it.\n","# Will be converted back to integers for SNN layer.\n","x_train = x_train / 255\n","x_test = x_test / 255\n","\n","# Add a channel dimension.\n","axis = 1 if backend.image_data_format() == 'channels_first' else -1\n","x_train = np.expand_dims(x_train, axis)\n","x_test = np.expand_dims(x_test, axis)\n","\n","# One-hot encode target vectors before saving for use in toolbox.\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Save dataset so SNN toolbox can find it.\n","np.savez_compressed(os.path.join(path_wd, 'x_test'), x_test)\n","np.savez_compressed(os.path.join(path_wd, 'y_test'), y_test)\n","# SNN toolbox will not do any training, but we save a subset of the training\n","# set so the toolbox can use it when normalizing the network parameters.\n","np.savez_compressed(os.path.join(path_wd, 'x_norm'), x_train[::10])\n","\n","# Pytorch doesn't support one-hot labels, so we undo it for training the ANN.\n","y_train = np.argmax(y_train, 1)\n","y_test = np.argmax(y_test, 1)"]},{"cell_type":"code","source":["class PytorchDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, target, transform=None):\n","        self.data = torch.from_numpy(data).float()\n","        self.target = torch.from_numpy(target).long()\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        x = self.data[index]\n","\n","        if self.transform:\n","            x = self.transform(x)\n","\n","        return x, self.target[index]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","trainset = torch.utils.data.DataLoader(PytorchDataset(x_train, y_train),\n","                                       batch_size=64)\n","testset = torch.utils.data.DataLoader(PytorchDataset(x_test, y_test),\n","                                      batch_size=64)"],"metadata":{"id":"a8lv6GM2iLJw","executionInfo":{"status":"ok","timestamp":1704302031803,"user_tz":0,"elapsed":1095,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# CREATE ANN #\n","##############\n","\n","# This section creates a CNN using pytorch, and trains it with backpropagation.\n","# There are no spikes involved at this point.\n","\n","# Create pytorch model from definition in separate script.\n","model = Model()\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","# Train model with backprop.\n","acc = 0\n","for epoch in range(3):\n","    for i, (xx, y) in enumerate(trainset):\n","        optimizer.zero_grad()\n","        outputs = model(xx)\n","        loss = criterion(outputs, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","    total = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for xx, y in testset:\n","            outputs = model(xx)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += y.size(0)\n","            correct += (predicted == y).sum().item()\n","    acc = correct / total\n","\n","print(\"Test accuracy: {:.2%}\".format(acc)) #86.37%"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GANB7cmhHzl","executionInfo":{"status":"ok","timestamp":1704301613328,"user_tz":0,"elapsed":45306,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}},"outputId":"f2634b72-552b-4265-977f-7e8fcc710d3d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy: 96.04%\n"]}]},{"cell_type":"code","source":["# Store weights so SNN Toolbox can find them.\n","model_name = 'cnn_model'\n","#torch.save(model.state_dict(), os.path.join(path_wd, model_name + '.pth'))\n","\n","#torch.load(model.state_dict(), os.path.join(path_wd, model_name + '.pth'))\n","\n","# model.load_state_dict(torch.load('/content/drive/MyDrive/Dissertation/project_code/ann_models/cnn_model.pkl'))\n","\n","torch.save(model.state_dict(), '/content/drive/MyDrive/Dissertation/project_code/ann_models/cnn_model.pkl')\n"],"metadata":{"id":"HfgsjHLQhAy1","executionInfo":{"status":"ok","timestamp":1704301937183,"user_tz":0,"elapsed":175,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# SNN TOOLBOX CONFIGURATION #\n","#############################\n","\n","# Create a config file with experimental setup for SNN Toolbox.\n","configparser = import_configparser()\n","config = configparser.ConfigParser()\n","\n","config['paths'] = {\n","    'path_wd': path_wd,             # Path to model.\n","    'dataset_path': path_wd,        # Path to dataset.\n","    'filename_ann': model_name      # Name of input model.\n","}\n","\n","config['tools'] = {\n","    'evaluate_ann': True,           # Test ANN on dataset before conversion.\n","    'normalize': True               # Normalize weights for full dynamic range.\n","}\n","\n","config['simulation'] = {\n","    'simulator': 'INI',             # Chooses execution backend of SNN toolbox.\n","    'duration': 50,                 # Number of time steps to run each sample.\n","    'num_to_test': 100,             # How many test samples to run.\n","    'batch_size': 50,               # Batch size for simulation.\n","    'keras_backend': 'tensorflow'   # Which keras backend to use.\n","}\n","\n","config['input'] = {\n","    'model_lib': 'pytorch'          # Input model is defined in pytorch.\n","}\n","\n","config['output'] = {\n","    'plot_vars': {                  # Various plots (slows down simulation).\n","        'spiketrains',              # Leave section empty to turn off plots.\n","        'spikerates',\n","        'activations',\n","        'correlation',\n","        'v_mem',\n","        'error_t'}\n","}"],"metadata":{"id":"PKOEKBK3g9dy","executionInfo":{"status":"ok","timestamp":1704302047791,"user_tz":0,"elapsed":330,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Store config file.\n","config_filepath = os.path.join(path_wd, 'config')\n","with open(config_filepath, 'w') as configfile:\n","    config.write(configfile)"],"metadata":{"id":"50ykWhq7g542","executionInfo":{"status":"ok","timestamp":1704302052490,"user_tz":0,"elapsed":200,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Need to copy model definition over to ``path_wd`` (needs to be in same dir as\n","# the weights saved above).\n","source_path = inspect.getfile(Model)\n","shutil.copyfile(source_path, os.path.join(path_wd, model_name + '.py'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"a4SIvBC0g4VW","executionInfo":{"status":"ok","timestamp":1704302053893,"user_tz":0,"elapsed":408,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}},"outputId":"aea972d1-53cc-4611-c108-c4534cf238b6"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Dissertation/project_code/ann_models/cnn_model.py'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# !pip install onnx\n","# !pip install onnxruntime\n","!pip install onnx2keras"],"metadata":{"id":"qA05SGH2kCAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704302234618,"user_tz":0,"elapsed":9237,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}},"outputId":"d575a44c-d756-4737-afba-82c4130d4fda"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx2keras\n","  Downloading onnx2keras-0.0.24.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from onnx2keras) (2.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx2keras) (1.23.5)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnx2keras) (1.15.0)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx2keras) (3.20.3)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (23.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (0.35.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (1.60.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->onnx2keras) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->onnx2keras) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->onnx2keras) (3.2.2)\n","Building wheels for collected packages: onnx2keras\n","  Building wheel for onnx2keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for onnx2keras: filename=onnx2keras-0.0.24-py3-none-any.whl size=24577 sha256=181dfa994e29acdd8068a39cca80b12c653d941fbde5409960ebb3c680a160ef\n","  Stored in directory: /root/.cache/pip/wheels/a1/fb/c9/349c27912022d104c7dd5f5d272595c33b1b959c4468d5e784\n","Successfully built onnx2keras\n","Installing collected packages: onnx2keras\n","Successfully installed onnx2keras-0.0.24\n"]}]},{"cell_type":"code","source":["# RUN SNN TOOLBOX #\n","###################\n","\n","main(config_filepath)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"YPmJhDhKgSQd","executionInfo":{"status":"error","timestamp":1704302242883,"user_tz":0,"elapsed":1337,"user":{"displayName":"OLUBUNMI ONWUEMENE","userId":"15338961923274852728"}},"outputId":"5f972a48-17b6-45b0-ec5c-c11a72377b56"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing INI simulator...\n","\n","Loading data set from '.npz' files in /content/drive/MyDrive/Dissertation/project_code/ann_models.\n","\n","WARNING: Ignored mismatch when loading pytorch state_dict.\n","Error(s) in loading state_dict for Model:\n","\tMissing key(s) in state_dict: \"trunk.0.weight\", \"trunk.0.bias\", \"branch1.0.weight\", \"branch1.0.bias\", \"branch2.0.weight\", \"branch2.0.bias\", \"head.0.weight\", \"head.0.bias\", \"classifier.1.weight\", \"classifier.1.bias\". \n","\tUnexpected key(s) in state_dict: \"network.0.weight\", \"network.0.bias\", \"network.1.weight\", \"network.1.bias\", \"network.1.running_mean\", \"network.1.running_var\", \"network.1.num_batches_tracked\", \"network.4.weight\", \"network.4.bias\", \"network.5.weight\", \"network.5.bias\", \"network.5.running_mean\", \"network.5.running_var\", \"network.5.num_batches_tracked\", \"network.8.weight\", \"network.8.bias\", \"network.9.weight\", \"network.9.bias\", \"network.9.running_mean\", \"network.9.running_var\", \"network.9.num_batches_tracked\", \"network.13.weight\", \"network.13.bias\". \n","Pytorch model was successfully ported to ONNX.\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-14d6fb19a662>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m###################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snntoolbox/bin/run.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snntoolbox/bin/utils.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(config, queue)\u001b[0m\n\u001b[1;32m     70\u001b[0m                                   \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_lib'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                                   '_input_lib')\n\u001b[0;32m---> 72\u001b[0;31m         input_model = model_lib.load(config.get('paths', 'path_wd'),\n\u001b[0m\u001b[1;32m     73\u001b[0m                                      config.get('paths', 'filename_ann'))\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snntoolbox/parsing/model_libs/pytorch_input_lib.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, filename)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0monnx2keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnx_to_keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# Port ONNX model to Keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     model_keras = onnx_to_keras(model_onnx, input_names, [input_shape[1:]],\n\u001b[0m\u001b[1;32m    119\u001b[0m                                 change_ordering=change_ordering, verbose=False)\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchange_ordering\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnx2keras/converter.py\u001b[0m in \u001b[0;36monnx_to_keras\u001b[0;34m(onnx_model, input_names, input_shapes, name_policy, verbose, change_ordering)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_image_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         AVAILABLE_CONVERTERS[node_type](\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mnode_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/onnx2keras/convolution_layers.py\u001b[0m in \u001b[0;36mconvert_conv\u001b[0;34m(node, params, layers, lambda_func, node_name, keras_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m             )\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# 1D conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: '/trunk/trunk.0/Conv_output_0/' is not a valid root scope name. A root scope name has to match the following pattern: ^[A-Za-z0-9.][A-Za-z0-9_.\\\\/>-]*$"]}]}]}